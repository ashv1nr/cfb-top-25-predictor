{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "The machine learning problem we are trying to solve is predicting the College Football Playoff Commitee's top 25 teams ranking. This matters beacuse th CFP Commitee's rankings are riddled with controversey year after year, as teams are constantly frustrated with their ranking. These rankings matter heavily, as they determine how prestigious of a bowl game teams play in, as well as who gets to compete for a national champsionship. There is very little information on what the commitee considers when they rank the teams, so our model could be used to give teams insight into what particular statistics the committe might value the most when they determine which teams should be ranked higher than others. Teams could then place emphasis on say making sure they have good passing offense or a positive turnover margin if the model shows teams who perform well in those categories are ranked well by the commitee.\n",
    "\n",
    "The dataset we are using we got from Kaggle at the following link: https://shorturl.at/glT68\n",
    "\n",
    "It holds data on over a 140 statistical categories(our features) on all FBS teams(the best 130 or so teams in the country) for every year the College Playoff Committe has existed, which is from 2014 to the present. Examples of features in our dataset are total points scored, offensive yards per play, sacks, and many more. We have over 800 records in our dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HkYcOMpSab7H"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_year = 14 # the first dataset is from 2014\n",
    "num_years = 9 # the datasets go from 2014-2022\n",
    "df_dict = {} # holds individual dataframes for each year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load every dataset into a dataframe and maps the year to its corresponding dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ikXrOv4BuZWb"
   },
   "outputs": [],
   "source": [
    "for year in range(first_year, first_year + num_years - 2):\n",
    "    df = pd.read_csv(\"cfb\" + str(year) + \".csv\")\n",
    "    df_dict[year] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adds the year the datasets are from as a column in each dataframe. We will drop the year feature eventually, but it will be helpful when we feature engineer later after merging the dataframes into one big dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(first_year, first_year + num_years - 2):\n",
    "    df = df_dict[year]\n",
    "    df['year'] = year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merges each individual dataframe into one big dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_set = sorted(list(df_dict.keys()))\n",
    "while len(key_set) > 1:\n",
    "  df0 = df_dict[key_set[0]]\n",
    "  df1 = df_dict[key_set[1]]\n",
    "  shared_columns = df0.columns.intersection(df1.columns)\n",
    "  df0 = df0.loc[:, shared_columns]\n",
    "  df1 = df1.loc[:, shared_columns]\n",
    "  df0 = pd.concat([df0, df1], ignore_index=True)\n",
    "  df_dict[key_set[0]] = df0\n",
    "  key_set.remove(key_set[1])\n",
    "df = df_dict[14] # our one big dataframe after merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two University of Miami's in our datasets. One in Florida and another in Ohio. We wanted to strip the parentheses off the location to help for a later step which also deals with parsing info out of parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vJYqoDPdepsb"
   },
   "outputs": [],
   "source": [
    "df['Team'] = df['Team'].str.replace('Miami \\(FL\\)', 'Miami FL', regex=True)\n",
    "df['Team'] = df['Team'].str.replace('Miami \\(OH\\)', 'Miami OH', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of games teams play can vary based on if they qualified for their conference championship or not, and during the Covid-19 pandemic, some conferences played a drastically different amount of games than others. For these reasons, it would make more sense to use win percentage rather than just number of wins in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wukLabE8HmLP"
   },
   "outputs": [],
   "source": [
    "df['win perct'] = df['Win'] / df['Games']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can subsequently drop the number of wins, lossess, and games played from our dataframe after creating our win percentage feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Win', axis=1)\n",
    "df = df.drop('Loss', axis=1)\n",
    "df = df.drop('Games', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conference a team is plays a big role in how the commitee ranks them. Most of the games teams play are against teams in the same conference, and some conferences have historically had higher performing teams. As a result, teams in these more elite conferences often have harder schedules, and thus it is critical to take into consideration the conference a team plays in when ranking them.\n",
    "\n",
    "In our datasets, the conference is not its own feature, it is attached to the feature for the team's name. Hence, we parse the conference from the team's name and add a column for the conference the team is in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "U15jotVuN-Bz"
   },
   "outputs": [],
   "source": [
    "df['conference'] = df['Team'].apply(lambda x: x[x.find('(') + 1: x.find(')')] if '(' in x and ')' in x else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we parse the conference from the team name feature and create the conference feature, we can remove the conference from the team name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dhxmD64bPKYv"
   },
   "outputs": [],
   "source": [
    "df['Team'] = df['Team'].apply(lambda x: x[:x.find('(')] if '(' in x else x)\n",
    "df['Team'] = df['Team'].str[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were a couple individual records with missing/wrong conferences, so we manually set the teams' conference to its correct one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XdiGPrZ3qQKe"
   },
   "outputs": [],
   "source": [
    "df.loc[df['conference'] == 'Independent', 'conference'] = 'FBS Independent'\n",
    "df.loc[(df['conference'] == '') & (df['Team'] == 'Ole Miss'), 'conference'] = 'SEC'\n",
    "df.loc[(df['conference'] == '') & (df['Team'] == 'Pittsburgh'), 'conference'] = 'ACC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our class label is if the team was ranked in the top 25 or not for the given year, so we utilize the lists below to add a column which holds a 1 if the team was ranked in the top 25 that year and a 0 if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "85JMF9n9T_Rw"
   },
   "outputs": [],
   "source": [
    "# lists of the CFP Commitee's top 25 ranking each year\n",
    "\n",
    "top25_14 = ['Alabama', 'Oregon', 'Florida St.', 'Ohio St.', 'Baylor',\n",
    "            'TCU', 'Mississippi St.', 'Michigan St.', 'Ole Miss', 'Arizona',\n",
    "            'Kansas St.', 'Georgia Tech', 'Georgia', 'UCLA', 'Arizona St.',\n",
    "            'Missouri', 'Clemson', 'Wisconsin', 'Auburn', 'Boise St.',\n",
    "            'Louisville', 'Utah', 'LSU', 'Southern California', 'Minnesota'] # top 25 from 2014\n",
    "\n",
    "top25_15 = ['Clemson', 'Alabama', 'Michigan St.', 'Oklahoma', 'Iowa',\n",
    "            'Stanford', 'Ohio St.', 'Notre Dame', 'Florida St.', 'North Carolina',\n",
    "            'TCU', 'Ole Miss', 'Northwestern', 'Michigan', 'Oregon',\n",
    "            'Oklahoma St.', 'Baylor', 'Houston', 'Florida', 'LSU',\n",
    "            'Navy', 'Utah', 'Tennessee', 'Temple', 'Southern California'] # top 25 from 2015\n",
    "\n",
    "top25_16 = ['Alabama', 'Clemson', 'Ohio St.', 'Washington', 'Penn St.',\n",
    "            'Michigan', 'Oklahoma', 'Wisconsin', 'Southern California', 'Colorado',\n",
    "            'Florida St.', 'Oklahoma St.', 'Louisville', 'Auburn', 'Western Mich.',\n",
    "            'West Virginia', 'Florida', 'Stanford', 'Utah', 'LSU',\n",
    "            'Tennessee', 'Virginia Tech', 'Pittsburgh', 'Temple', 'Navy'] # top 25 from 2016\n",
    "\n",
    "top25_17 = ['Clemson', 'Oklahoma', 'Georgia', 'Alabama', 'Ohio St.',\n",
    "            'Wisconsin', 'Auburn', 'Southern California', 'Penn St.', 'Miami FL',\n",
    "            'Washington', 'UCF', 'Stanford', 'Notre Dame', 'TCU',\n",
    "            'Michigan St.', 'LSU', 'Washington St.', 'Oklahoma St.', 'Memphis',\n",
    "            'Northwestern', 'Virginia Tech', 'Mississippi St.', 'NC State', 'Boise St.'] # top 25 from 2017\n",
    "\n",
    "top25_18 = ['Alabama', 'Clemson', 'Notre Dame', 'Oklahoma', 'Georgia',\n",
    "            'Ohio St.', 'Michigan', 'UCF', 'Washington', 'Florida',\n",
    "            'LSU', 'Penn St.', 'Washington St.', 'Kentucky', 'Texas',\n",
    "            'West Virginia', 'Utah', 'Mississippi St.', 'Texas A&M', 'Syracuse',\n",
    "            'Fresno St.', 'Northwestern', 'Missouri', 'Iowa St.', 'Boise St.'] # top 25 from 2018\n",
    "\n",
    "top25_19 = ['LSU', 'Ohio St.', 'Clemson', 'Oklahoma', 'Georgia',\n",
    "            'Oregon', 'Baylor', 'Wisconsin', 'Florida', 'Penn St.',\n",
    "            'Utah', 'Auburn', 'Alabama', 'Michigan', 'Notre Dame',\n",
    "            'Iowa', 'Memphis', 'Minnesota', 'Boise St.', 'Appalachian St.',\n",
    "            'Cincinnati', 'Southern California', 'Navy', 'Virginia', 'Oklahoma St.'] # top 25 from 2019\n",
    "\n",
    "top25_20 = ['Alabama', 'Clemson', 'Ohio St.', 'Notre Dame', 'Texas A&M',\n",
    "            'Oklahoma', 'Florida', 'Cincinnati', 'Georgia', 'Iowa St.',\n",
    "            'Indiana', 'Coastal Carolina', 'North Carolina', 'Northwestern', 'Iowa',\n",
    "            'BYU', 'Southern California', 'Miami FL', 'Louisiana', 'Texas',\n",
    "            'Oklahoma St.', 'San Jose St.', 'NC State', 'Tulsa', 'Oregon'] # top 25 from 2020\n",
    "\n",
    "top25_21 = ['Alabama', 'Michigan', 'Georgia', 'Cincinnati', 'Notre Dame',\n",
    "            'Ohio St.', 'Baylor', 'Ole Miss', 'Oklahoma St.', 'Michigan St.',\n",
    "            'Utah', 'Pittsburgh', 'BYU', 'Oregon', 'Iowa',\n",
    "            'Oklahoma', 'Wake Forest', 'NC State', 'Clemson', 'Houston',\n",
    "            'Arkansas', 'Kentucky', 'Louisiana', 'San Diego St.', 'Texas A&M'] # top 25 from 2021\n",
    "\n",
    "top25_22 = ['Georgia', 'Michigan', 'TCU', 'Ohio St.', 'Alabama',\n",
    "            'Tennessee', 'Clemson', 'Utah', 'Kansas St.', 'Southern California',\n",
    "            'Penn St.', 'Washington', 'Florida St.', 'Oregon St.', 'Oregon',\n",
    "            'Tulane', 'LSU', 'UCLA', 'South Carolina', 'Texas',\n",
    "            'Notre Dame', 'Mississippi St.', 'NC State', 'Troy', 'UTSA'] # top 25 from 2022\n",
    "\n",
    "top25_dict = {14: top25_14, 15: top25_15, 16: top25_16, 17: top25_17, 18: top25_18,\n",
    "              19: top25_19, 20: top25_20, 21: top25_21, 22: top25_22} # dictionary to be able to grab rankings for a desired year\n",
    "\n",
    "df['top 25'] = df.apply(lambda row: 1 if row['Team'] in top25_dict.get(row['year'], []) else 0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we create the feature that says if a team was in the top 25 or not for the given year, we can drop the year column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('year', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "25IXQbUTEtRn",
    "outputId": "ec1d24d3-e861-443a-e874-7292bffd688e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Off.Rank</th>\n",
       "      <th>Off.Plays</th>\n",
       "      <th>Off.Yards</th>\n",
       "      <th>Off.Yards.Play</th>\n",
       "      <th>Off.TDs</th>\n",
       "      <th>Off.Yards.per.Game</th>\n",
       "      <th>Def.Rank</th>\n",
       "      <th>Def.Plays</th>\n",
       "      <th>Yards.Allowed</th>\n",
       "      <th>...</th>\n",
       "      <th>Opponents.Intercepted</th>\n",
       "      <th>Turnovers.Gain</th>\n",
       "      <th>Fumbles.Lost</th>\n",
       "      <th>Interceptions.Thrown.y</th>\n",
       "      <th>Turnovers.Lost</th>\n",
       "      <th>Turnover.Margin</th>\n",
       "      <th>Avg.Turnover.Margin.per.Game</th>\n",
       "      <th>win perct</th>\n",
       "      <th>conference</th>\n",
       "      <th>top 25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Akron</td>\n",
       "      <td>88</td>\n",
       "      <td>891</td>\n",
       "      <td>4479</td>\n",
       "      <td>5.03</td>\n",
       "      <td>32</td>\n",
       "      <td>373.3</td>\n",
       "      <td>44</td>\n",
       "      <td>859</td>\n",
       "      <td>4453</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>-2</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>MAC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>17</td>\n",
       "      <td>1018</td>\n",
       "      <td>6783</td>\n",
       "      <td>6.66</td>\n",
       "      <td>67</td>\n",
       "      <td>484.5</td>\n",
       "      <td>12</td>\n",
       "      <td>945</td>\n",
       "      <td>4598</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>-2</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>SEC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>25</td>\n",
       "      <td>1139</td>\n",
       "      <td>6491</td>\n",
       "      <td>5.70</td>\n",
       "      <td>55</td>\n",
       "      <td>463.6</td>\n",
       "      <td>103</td>\n",
       "      <td>1115</td>\n",
       "      <td>6314</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>Pac-12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona St.</td>\n",
       "      <td>34</td>\n",
       "      <td>975</td>\n",
       "      <td>5750</td>\n",
       "      <td>5.90</td>\n",
       "      <td>54</td>\n",
       "      <td>442.3</td>\n",
       "      <td>81</td>\n",
       "      <td>964</td>\n",
       "      <td>5422</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>Pac-12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>60</td>\n",
       "      <td>916</td>\n",
       "      <td>5278</td>\n",
       "      <td>5.76</td>\n",
       "      <td>52</td>\n",
       "      <td>406.0</td>\n",
       "      <td>10</td>\n",
       "      <td>821</td>\n",
       "      <td>4204</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>SEC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>42</td>\n",
       "      <td>690</td>\n",
       "      <td>3804</td>\n",
       "      <td>5.51</td>\n",
       "      <td>28</td>\n",
       "      <td>422.7</td>\n",
       "      <td>5</td>\n",
       "      <td>561</td>\n",
       "      <td>2675</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>Big 12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>Western Ky.</td>\n",
       "      <td>120</td>\n",
       "      <td>699</td>\n",
       "      <td>3200</td>\n",
       "      <td>4.58</td>\n",
       "      <td>21</td>\n",
       "      <td>290.9</td>\n",
       "      <td>21</td>\n",
       "      <td>741</td>\n",
       "      <td>3700</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>-3</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>C-USA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>Western Mich.</td>\n",
       "      <td>15</td>\n",
       "      <td>392</td>\n",
       "      <td>2878</td>\n",
       "      <td>7.34</td>\n",
       "      <td>32</td>\n",
       "      <td>479.7</td>\n",
       "      <td>60</td>\n",
       "      <td>428</td>\n",
       "      <td>2398</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>-3</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>MAC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>93</td>\n",
       "      <td>431</td>\n",
       "      <td>2153</td>\n",
       "      <td>5.00</td>\n",
       "      <td>17</td>\n",
       "      <td>358.8</td>\n",
       "      <td>1</td>\n",
       "      <td>332</td>\n",
       "      <td>1581</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>-3</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Big Ten</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>82</td>\n",
       "      <td>409</td>\n",
       "      <td>2237</td>\n",
       "      <td>5.47</td>\n",
       "      <td>17</td>\n",
       "      <td>372.8</td>\n",
       "      <td>16</td>\n",
       "      <td>399</td>\n",
       "      <td>1968</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>Mountain West</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>859 rows Ã— 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Team  Off.Rank  Off.Plays  Off.Yards  Off.Yards.Play  Off.TDs  \\\n",
       "0            Akron        88        891       4479            5.03       32   \n",
       "1          Alabama        17       1018       6783            6.66       67   \n",
       "2          Arizona        25       1139       6491            5.70       55   \n",
       "3      Arizona St.        34        975       5750            5.90       54   \n",
       "4         Arkansas        60        916       5278            5.76       52   \n",
       "..             ...       ...        ...        ...             ...      ...   \n",
       "854  West Virginia        42        690       3804            5.51       28   \n",
       "855    Western Ky.       120        699       3200            4.58       21   \n",
       "856  Western Mich.        15        392       2878            7.34       32   \n",
       "857      Wisconsin        93        431       2153            5.00       17   \n",
       "858        Wyoming        82        409       2237            5.47       17   \n",
       "\n",
       "     Off.Yards.per.Game  Def.Rank  Def.Plays  Yards.Allowed  ...  \\\n",
       "0                 373.3        44        859           4453  ...   \n",
       "1                 484.5        12        945           4598  ...   \n",
       "2                 463.6       103       1115           6314  ...   \n",
       "3                 442.3        81        964           5422  ...   \n",
       "4                 406.0        10        821           4204  ...   \n",
       "..                  ...       ...        ...            ...  ...   \n",
       "854               422.7         5        561           2675  ...   \n",
       "855               290.9        21        741           3700  ...   \n",
       "856               479.7        60        428           2398  ...   \n",
       "857               358.8         1        332           1581  ...   \n",
       "858               372.8        16        399           1968  ...   \n",
       "\n",
       "     Opponents.Intercepted  Turnovers.Gain  Fumbles.Lost  \\\n",
       "0                       13              24            12   \n",
       "1                       11              20            12   \n",
       "2                       13              26             8   \n",
       "3                       14              27             4   \n",
       "4                       12              24            11   \n",
       "..                     ...             ...           ...   \n",
       "854                     10              12             6   \n",
       "855                      5               9            10   \n",
       "856                      2               3             4   \n",
       "857                      4               8             5   \n",
       "858                      4              10             4   \n",
       "\n",
       "     Interceptions.Thrown.y  Turnovers.Lost  Turnover.Margin  \\\n",
       "0                        14              26               -2   \n",
       "1                        10              22               -2   \n",
       "2                        10              18                8   \n",
       "3                         9              13               14   \n",
       "4                         6              17                7   \n",
       "..                      ...             ...              ...   \n",
       "854                       3               9                3   \n",
       "855                       2              12               -3   \n",
       "856                       2               6               -3   \n",
       "857                       6              11               -3   \n",
       "858                       5               9                1   \n",
       "\n",
       "     Avg.Turnover.Margin.per.Game  win perct     conference  top 25  \n",
       "0                           -0.17   0.416667            MAC       0  \n",
       "1                           -0.14   0.857143            SEC       1  \n",
       "2                            0.57   0.714286         Pac-12       1  \n",
       "3                            1.08   0.769231         Pac-12       1  \n",
       "4                            0.54   0.538462            SEC       0  \n",
       "..                            ...        ...            ...     ...  \n",
       "854                          0.33   0.555556         Big 12       0  \n",
       "855                         -0.27   0.454545          C-USA       0  \n",
       "856                         -0.50   0.666667            MAC       0  \n",
       "857                         -0.50   0.500000        Big Ten       0  \n",
       "858                          0.17   0.333333  Mountain West       0  \n",
       "\n",
       "[859 rows x 145 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conference_ranked_counts = df.groupby('conference')['top 25'].sum()\n",
    "conference_ranked_counts.plot(kind='bar')\n",
    "plt.xlabel('Conference')\n",
    "plt.ylabel('Number of Ranked Teams')\n",
    "plt.title('Number of Ranked Teams in Each Conference')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conference_ranked_counts = df.groupby('top 25')['Turnover.Margin'].mean()\n",
    "conference_ranked_counts.plot(kind='bar')\n",
    "plt.xlabel('top 25')\n",
    "plt.ylabel('avg turnover margin')\n",
    "plt.title('avg turnover margin for ranked vs unranked teams')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conference_ranked_counts = df.groupby('top 25')['Off.Yards.Play'].mean()\n",
    "conference_ranked_counts.plot(kind='bar')\n",
    "plt.xlabel('top 25')\n",
    "plt.ylabel('avg off yards per play')\n",
    "plt.title('avg yards per play for ranked vs unranked teams')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(df['conference'])\n",
    "one_hot = one_hot.astype('int')\n",
    "#df = pd.get_dummies(df, columns = ['conference'])\n",
    "df = df.drop('conference', axis = 1)\n",
    "df.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_string_df = df.drop(['Team'], axis=1)\n",
    "\n",
    "def convert_time(str_time):\n",
    "    minutes, seconds = str_time.split(':')\n",
    "    return (int(minutes) * 60) + int(seconds)\n",
    "\n",
    "no_string_df['Time.of.Possession'] = no_string_df['Time.of.Possession'].apply(lambda x: convert_time(x))\n",
    "no_string_df['Average.Time.of.Possession.per.Game'] = no_string_df['Average.Time.of.Possession.per.Game'].apply(lambda x: convert_time(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "scaler = StandardScaler()\n",
    "pca = PCA()\n",
    "scaled_df = scaler.fit_transform(no_string_df)\n",
    "scaled_df = pd.DataFrame(scaled_df, columns=no_string_df.columns)\n",
    "scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = no_string_df.drop('top 25', axis=1)\n",
    "labels = no_string_df['top 25'].values.ravel()\n",
    "scaled_features = scaled_df.drop('top 25', axis=1)\n",
    "scaled_labels = scaled_df['top 25'].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees with different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "param_grid = {'max_depth': [5, 10, 15, 20], 'min_samples_leaf': [5, 10, 15, 20], 'max_features': [5, 10, 15]}\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\n",
    "nested_scores = cross_val_score(grid_search, features, labels, cv=5)\n",
    "print(\"Average accuracy:\", nested_scores.mean() * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "scores = cross_val_score(gnb, features, labels, cv=10, scoring='accuracy')\n",
    "print(\"Average accuracy:\", scores.mean() * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "param_grid = {'pca__n_components': list(range(5, 19)), 'knn__n_neighbors': list(range(1, 25))}\n",
    "\n",
    "gr_sch = GridSearchCV(pl, param_grid, cv = 5)\n",
    "gr_sch.fit(features, labels)\n",
    "outer_loop = KFold(n_splits = 5, shuffle = True, random_state = 21)\n",
    "nested_scores = cross_val_score(gr_sch, features, labels, cv = outer_loop)\n",
    "accuracy = nested_scores.mean()\n",
    "print(\"Nested CV accuracy:\", accuracy * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_pl = Pipeline([('scaler', StandardScaler()), ('svc', SVC())])\n",
    "prm_grd = { 'svc__C': [0.1, 1, 10, 100], 'svc__kernel': ['linear', 'rbf', 'poly']}\n",
    "gr_sch = GridSearchCV(svm_pl, prm_grd, cv = 5)\n",
    "predictions = cross_val_predict(gr_sch, features, labels, cv = outer_loop)\n",
    "accuracy = cross_val_score(gr_sch, features, labels, cv = 5, scoring = 'accuracy').mean()\n",
    "print(\"Accuracy:\", accuracy * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def run_nn():\n",
    "    pl = Pipeline([('scaler', StandardScaler()), ('mlp', MLPClassifier(max_iter = 1000, random_state = 21))])\n",
    "    prm_grd = {'mlp__hidden_layer_sizes': [(30,), (40,), (50,), (60,)], 'mlp__activation': ['logistic', 'tanh', 'relu']}\n",
    "    grid_search = GridSearchCV(pl, prm_grd, cv=5)\n",
    "    accuracy = cross_val_score(grid_search, features, labels, cv = 5, scoring = 'accuracy').mean()\n",
    "    print(\"Accuracy:\", accuracy * 100, \"%\")\n",
    "  \n",
    "\n",
    "run_nn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "gnb = GaussianNB()\n",
    "predicted_labels = cross_val_predict(gnb, features, labels, cv=10)\n",
    "rf_clf = RandomForestClassifier(random_state = 21)\n",
    "prm_grd = {'n_estimators': [50, 100, 150]}\n",
    "grd_sch = GridSearchCV(rf_clf, prm_grd, cv = 5)\n",
    "predictions = cross_val_predict(grd_sch, features, labels, cv = 5)\n",
    "cls_rpt = classification_report(labels, predicted_labels)\n",
    "print(cls_rpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
